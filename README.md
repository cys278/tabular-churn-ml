# ğŸ“Š Tabular Churn Prediction (Baseline)

An end-to-end machine learning pipeline that predicts **customer churn** (whether a customer is likely to leave a service).
Built with **scikit-learn + FastAPI** and using the **Telco Customer Churn dataset**.

---

## ğŸš€ Project Structure

```
tabular-churn-ml/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/         <- Original dataset (Telco churn CSV)
â”‚   â””â”€â”€ processed/   <- Train/val/test splits
â”‚
â”œâ”€â”€ models/          <- Saved trained model (churn_model.pkl)
â”‚
â”œâ”€â”€ notebooks/       <- Jupyter notebooks for exploration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ download_data.py   # Download dataset
â”‚   â”œâ”€â”€ data.py            # Split data into train/val/test
â”‚   â”œâ”€â”€ train.py           # Train baseline model
â”‚   â””â”€â”€ app.py             # FastAPI app serving predictions
â”‚
â”œâ”€â”€ tests/           <- Unit tests (future)
â”‚
â”œâ”€â”€ requirements.txt <- Python dependencies
â””â”€â”€ README.md        <- Project documentation
```

---

## âš™ï¸ Setup

### 1. Clone repo

```bash
git clone https://github.com/<your-username>/tabular-churn-ml.git
cd tabular-churn-ml
```

### 2. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“¥ Data

Download Telco Churn dataset from Kaggle automatically:

```bash
python3 src/download_data.py
```

Split into train/val/test:

```bash
python3 src/data.py
```

---

## ğŸ‹ï¸ Training

Train a baseline Logistic Regression model:

```bash
python3 src/train.py
```

This will:

* Preprocess numeric & categorical features
* Train a logistic regression model
* Print evaluation metrics (AUC, F1, precision, recall)
* Save model â†’ `models/churn_model.pkl`

---

## ğŸŒ API (Serving Predictions)

Run FastAPI locally:

```bash
uvicorn src.app:app --reload
```

* Open docs: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

Example request (JSON):

```json
{
  "customerID": "1234-ABCD",
  "gender": "Female",
  "SeniorCitizen": 0,
  "Partner": "Yes",
  "Dependents": "No",
  "tenure": 5,
  "PhoneService": "Yes",
  "MultipleLines": "No",
  "InternetService": "Fiber optic",
  "OnlineSecurity": "No",
  "OnlineBackup": "Yes",
  "DeviceProtection": "No",
  "TechSupport": "No",
  "StreamingTV": "Yes",
  "StreamingMovies": "Yes",
  "Contract": "Month-to-month",
  "PaperlessBilling": "Yes",
  "PaymentMethod": "Electronic check",
  "MonthlyCharges": 89.5,
  "TotalCharges": 445.0
}
```

Example response:

```json
{
  "prob": 0.734,
  "label": 1
}
```

---

## âœ… Definition of Done

* Data pipeline (`download_data.py`, `data.py`)
* Baseline churn model trained (`train.py`)
* Model served via FastAPI (`app.py`)
* Example request/response tested
* Documentation (`README.md`)

---

## ğŸ“Œ Next Steps (Future Sprints)

* Add Streamlit/Gradio demo UI
* Add SHAP explainability (`top_factors`)
* Try tree-based models (XGBoost, LightGBM)
* Add Dockerfile for deployment
